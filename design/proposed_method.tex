\section{Proposed Method} 
In chapter 1, we learned a generative model of gene expression time
series data using a VAE framework, where we learned a regularized latent space representation of latent
variables $z$ by reconstructing the data $x$ through an encoder-decoder architecture. We can start
thinking about the binding element design problem in the same manner.

Let's define $x_p$ as input binding site information. We want to predict a binding element $x_e$
given $x_p$. To achieve this task, we again formulate a generative story: $x_e$ is generated from
latent variables $z$, which can be modeled by a decoder/generator network which models the
distribution $P(x_e|z)$. And we can employ an encoder network modeling $P(z|x_p)$ to achieve the
latent information $z$ from the input $x_e$.

Now, to formally achieve the prediction task, we start with writing out the conditional distribution,
$P(x_e, z|x_p)$ which we would like to maximize and predicts the argument $x_e$ and $z$ that maximizes it.

\begin{align*}
        P(x_e,z|x_p) = P(x_e|z,x_p)P(z|x_p) \;\;\; \text{using Bayes' rule}\numberthis
\end{align*}
Here, we assume a hierarchical Bayesian setting where given the latent variable $z$, $x_e$ is
generated independent of $x_p$ i.e. $P(x_e|z,x_p) = P(x_e|z)$. Now we can write the following,
\begin{align*}
P(x_e,z|x_p) &= P(x_e|z)P(z|x_p) \numberthis \\
\end{align*}
Now, we can model the posterior of $z$, $P(z | x_p)$ as a Gaussian $N(z_{\mu}, z_{\Sigma})$. This
can be modeled by outputing the parameters $z_{\mu}, z_{\Sigma}$ from an encoder network $E(x_p)$.
A value of $z$ can be sampled from this distribution now using the reparamtrization trick described
in \citet{Kingma2014}, similar to as described in Chapter 1 for RVAgene. This process along with a
KL loss with a prior on $z$ $p(z) = N(0,\bI)$ ensures a regularized latent space which is important
for generating meaningful data. Therefore,
\begin{align*}
        z_{\mu}, z_{\Sigma} &= E(x_p) \numberthis \\
        \hat{z} &= z_{\mu} + \epsilon \cdot z_{\Sigma} \;\; where \;\; \epsilon \sim N(0,\bI) \numberthis \\
        \hat{x}_e &= argmax_{x_e}p(x_e | \hat{z}) = G(\hat{z}) \;\; \numberthis \label{final_prediction_architecture} 
\end{align*}
%\implies \text{prediction } \hat{x}_e, \hat{z} &= argmax_{x_e,z} P(x_e,z|x_p) \numberthis \\
%&= argmax_{x_e,z} P(x_e|z)P(z|x_p)  \\
%\implies  \hat{z} = argmax_{z} P(z|x_p); & \;\;\;\;\hat{x}_e = argmax_{x_e} P(x_e | \hat{z}) \numberthis \\
%\implies \hat{z} = E(x_p); & \;\;\;\; \hat{x}_e = G(\hat{z}) \numberthis
The functions $E(x_p)$ and $G(\hat{z})$ in \ref{final_prediction_architecture} represent the
encoder and generator functions respectively both of which are parametrized by neural networks. 

Now, the encoder-generator framework described above is suitable for prediction, however it's
difficult to train it in a straight forward manner. For RVAgene \red{(cite)} we were able to use
reconstruction based method to train because the input of encoder and output of decoder was the same.
Here, they are different. This constitutes a proper scenario to employ an adversarial training
scheme as employed by GANs \citep{goodfellow2014generative}.

Given a training dataset $X$ consisting of $n$ datapoints, where $X_i = (x_p^i, x_e^i) \;\; i \in
\{0,..., n-1\}$, we now describe
how to train the generative model described in \ref{final_prediction_architecture}. We assign a
label variable $y = 1$ for all datatpoints in the training data $X$. Now, assume we have some
datapairs $F = (x_p^i, \hat{x}_e^i) \;\; i \in \{0,..., m-1\}$ generated by the encoder-generator
system given $x_p^i$s as input. We assign these datapoints a label $y = 0$. Now, we can train a
neural network $D$ discriminating between the datasets X and F i.e. the discriminator $D$ is
predicting $P(y = 1 | x_p, x_e)$. It is clear that the better the enocder-generator system is in
predicting binding element given a protein surface, the harder the job of the discriminator becomes.
We take advantage of this fact and teach the encoder-generator network to try to best the
discriminator and vice versa. The two networks play the following minimax game:
\begin{align*}
        min_{G,E}max_{D} V(D, E, G) &= \bE_{x_p, x_e \sim P_X}\bigg{[}log D(x_p, x_e)\bigg{]} + \bE_{x_p \sim
        P_{x_p}}\bigg{[}log(1 - D(x_p,G(\hat{z}))) + KL(N(z_{\mu}, z_{\Sigma}) || N(0, \bI))\bigg{]} \numberthis \label{gan_game}\\
        &where \; \hat{z} = z_{\mu} + \epsilon z_{\Sigma} \;\; where \; \epsilon \sim N(0,\bI)\; and \;
        z_{\mu}, z_{\sigma} = E(x_p)
\end{align*}
In eq. \ref{gan_game} above $P_X$ represents the full training data distribution and $P_{x_p}$
represents the marginal distribution of binding sites in the training data. 

If we call the generated distribution of $x_p, \hat{x}_e$ as $p_g$, as described and proven in
\citet{goodfellow2014generative} this adversarial game 
eventually results into the generated data distribution becoming same as the training data
distribution $P_x$, which
happens at the point when both the $(E, G)$ and $D$ network cannot improve anymore.
