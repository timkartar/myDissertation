


\section{Introduction}
Dynamic changes in gene expression control the transcriptional state of a cell, and are responsible for modulating cellular states and fates. Gene expression dynamics are in turn controlled by cell-internal and external signaling networks. Despite the noisiness of gene expression in single cells \citep{raj2008nature}, over time or over populations of cells, predictable patterns emerge. Here we address the challenge of classifying and predicting gene expression dynamics across large groups of genes.
\par 
Machine learning (and deep learning in particular) has led to recent advances in our ability to explain or predict biological phenomena \citep{ching2018opportunities}. Deep learning modeling via autoencoders \citep{hinton2006reducing} and variational autoencoders \citep{Kingma2014} has been central to progress in the field. Autoencoders learn two functions: one to encode each input data point to a low dimensional point, and another (the decoder) to reconstruct the original data point from the low dimensional representation. Variational autoencoders (VAEs) build on this architecture and instead encode input data points as distributions; VAEs are less prone to overfitting and can offer meaningful representations of biological features in the latent space \citep{way2017extracting}.


%Another challenge is assessment i.e. how much better these methods are compared to some traditional methods for performing similar tasks because often the reported performances of these methods rely on heavy hyperparameter tuning [cite greene] and generalizing a model for different datasets might be hard with a given setting and hence doing a study of straightforward comparison of these methods is hard. The aspect of interpretability of deep networks also remain hard to address [cite stg interpretrable]. 
\par 
Single-cell mRNA sequencing (scRNA-seq) data present appealing sources of data for deep learning models, given their size and complexity \citep{svensson2018exponential}. Deep learning models have been used to analyze \scrna data and address a variety of challenges. Autoencoders have been developed to perform noise removal/batch correction \citep{deng2019scalable, eraslan2019single, wang2019data}, imputation \citep{talwar2018autoimpute}, and visualization \& clustering \citep{lin2017using}. VAEs have been developed for the visualization and clustering of \scrna data \citep{ding2018interpretable, wang2018vasc}, and can provide a broad framework for generative modeling of \scrna data \citep{lopez2018deep}: scVI can be used for batch correction, clustering, visualization, and differential expression testing.
%These methods offer exciting new avenues for discovery from single-cell profiling experiments, although limitations remain \citep{zheng2019emerging}.
\par 
The methods described above for single-cell data analysis by deep learning focus primarily on cell-centric tasks; here we are interested in gene-centric inference. Particularly, we are interested in characterizing dynamic changes in gene expression. These can be either changes with respect to real time or ``pseudotime,'' the latter referring to the ordering of single cells along an axis describing a dynamic cell process such as development or stem cell differentiation (see methods overview in \citep{saelens2019comparison}). We can interpret any \scrna data as gene expression time series data, given an appropriate underlying temporal process, either in terms of real (experimental) time (low resolution: around $2-20$ data points) or pseudotime (high resolution: $10^3-10^6$ data points). \citet{McDowell2018} introduced a non-parametric hierarchical Bayesian method (DPGP) to model such data. Using a Gaussian process to cluster temporal gene profiles and a Dirichlet process to generate the Gaussian processes, DPGP offers powerful and intuitive means with which to cluster gene expression time series data. However, since learning Gaussian processes is equivalent to a fully agnostic search in function space, training DPGP is computationally intensive and difficult to parallelize.  
\par
Clustering relies on strong assumptions about the underlying structure of the data. Even for methods that move away from hard clustering towards probabilistic methods for cell type assignment \citep{jetka2018information, zhu2019semisoft}, assumptions remain and under certain conditions a continuous representation of the data may be better. 
Here we take such an approach, and seek to find a low dimensional representation of the data, on which further analyses (including but not limited to clustering) can be performed. VAEs are an obvious choice, given their success on other \scrna analysis tasks, but modeling temporal changes with a feed-forward VAE would be equivalent to a fully agnostic search, similar to learning a Gaussian process. Recurrent networks offer well-established architectures for learning sequential and temporal data, and have been successfully combined with VAEs  \citep{Fabius2015}. We use a recurrent network architecture to take advantage of the structure in the data.
\par 
We introduce a recurrent variational autoencoder for modeling gene dynamics from \scrna data (RVAgene). RVAgene learns two functions during training, parameterized by encoder and decoder networks. The encoder network projects the training data into latent space (we use a 2 or 3 dimensions in order to visualize, though there are no inherent limits). The decoder network learns a reconstruction of training genes from their latent representation. RVAgene facilitates clustering of other characterization of gene profiles in the latent space. By sampling points from the latent space and decoding them, RVAgene provides means to generate new gene expression time series data, drawn from the biological process that was encoded. Overall, RVAgene serves as a multipurpose generative model for exploring gene expression time-series data. 
\par 
The remainder of the paper is structured as follows: we next present methodological details and development of RVAgene. We produce a synthetic gene expression time-series dataset with innate cluster structure, and demonstrate the accuracy of RVAgene on these data.
{We then explore two biological datasets with RVAgene: a \scrna dataset on stem cell differentiation over pseudotime, on which we demonstrate the advantages of RVAgene over alternative approaches; and a bulk RNA-seq dataset describing dynamic responses to kidney injury, on which we demonstrate the potential for biological discovery. We also present evidence for the efficiency and scalability of RVAgene, and we conclude by discussing its key features and limitations, in light of recent advances in machine learning that will pave the way for future work in these directions.
}
